{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjaEcc2VftAj1fo9DQHnpA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulatira/Convert_audio_to_text/blob/main/data_aug_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p cifar\n",
        "!pip install argparse\n",
        "import tensorflow\n",
        "import keras\n",
        "import tensorflow.keras.datasets\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "xw_wcRtJjgO5",
        "outputId": "05a339b5-8761-4b6c-ef59-bc05a752754e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C2Q5rPenTAJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa95905-6c38-4150-8e87-f3d133611ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Base augmentations operators.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "# ImageNet code should change this value\n",
        "IMAGE_SIZE = 32\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "    Args:\n",
        "        level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "        maxval: Maximum value that the operation can have. This will be scaled to level/PARAMETER_MAX.\n",
        "\n",
        "    Returns:\n",
        "        An int that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
        "\n",
        "    Args:\n",
        "        level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "        maxval: Maximum value that the operation can have. This will be scaled to level/PARAMETER_MAX.\n",
        "\n",
        "    Returns:\n",
        "        A float that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return float(level) * maxval / 10.\n",
        "\n",
        "\n",
        "def sample_level(n):\n",
        "    return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "    return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "    return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 4)\n",
        "    return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "    degrees = int_parameter(sample_level(level), 30)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        degrees = -degrees\n",
        "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 256)\n",
        "    return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                             Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                             resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                             Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                             resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                             Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                             resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                             Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                             resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y\n",
        "]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, color, contrast, brightness, sharpness\n",
        "]\n",
        "\n",
        "print(\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Reference implementation of AugMix's data augmentation method in numpy.\"\"\"\n",
        "# import augmentations\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# CIFAR-10 constants\n",
        "MEAN = [0.4914, 0.4822, 0.4465]\n",
        "STD = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "\n",
        "def normalize(image):\n",
        "  \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
        "  image = image.transpose(2, 0, 1)  # Switch to channel-first\n",
        "  mean, std = np.array(MEAN), np.array(STD)\n",
        "  image = (image - mean[:, None, None]) / std[:, None, None]\n",
        "  return image.transpose(1, 2, 0)\n",
        "\n",
        "\n",
        "def apply_op(image, op, severity):\n",
        "  image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
        "  pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
        "  pil_img = op(pil_img, severity)\n",
        "  return np.asarray(pil_img) / 255.\n",
        "\n",
        "\n",
        "def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "\n",
        "  Args:\n",
        "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
        "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
        "    width: Width of augmentation chain\n",
        "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
        "      from [1, 3]\n",
        "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
        "\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  ws = np.float32(\n",
        "      np.random.dirichlet([alpha] * width))\n",
        "  m = np.float32(np.random.beta(alpha, alpha))\n",
        "\n",
        "  mix = np.zeros_like(image)\n",
        "  for i in range(width):\n",
        "    image_aug = image.copy()\n",
        "    d = depth if depth > 0 else np.random.randint(1, 4)\n",
        "    for _ in range(d):\n",
        "      op = np.random.choice(augmentations.augmentations)\n",
        "      image_aug = apply_op(image_aug, op, severity)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * normalize(image_aug)\n",
        "\n",
        "  mixed = (1 - m) * normalize(image) + m * mix\n",
        "  return mixed\n",
        "\n",
        "print(\"done\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8aawHwxjIec",
        "outputId": "918d5590-b3ef-456a-d945-38fefb09b8c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Main script to launch AugMix training on CIFAR-10/100.\n",
        "\n",
        "Supports WideResNet, AllConv, ResNeXt models on CIFAR-10 and CIFAR-100 as well\n",
        "as evaluation on CIFAR-10-C and CIFAR-100-C.\n",
        "\n",
        "Example usage:\n",
        "  `python cifar.py`\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "#import augmentations\n",
        "import allconv\n",
        "from models.cifar.allconv import AllConvNet\n",
        "import numpy as np\n",
        "from third_party.ResNeXt_DenseNet.models.densenet import densenet\n",
        "from third_party.ResNeXt_DenseNet.models.resnext import resnext29\n",
        "from third_party.WideResNet_pytorch.wideresnet import WideResNet\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "    description='Trains a CIFAR Classifier',\n",
        "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "parser.add_argument(\n",
        "    '--dataset',\n",
        "    type=str,\n",
        "    default='cifar10',\n",
        "    choices=['cifar10', 'cifar100'],\n",
        "    help='Choose between CIFAR-10, CIFAR-100.')\n",
        "parser.add_argument(\n",
        "    '--model',\n",
        "    '-m',\n",
        "    type=str,\n",
        "    default='wrn',\n",
        "    choices=['wrn', 'allconv', 'densenet', 'resnext'],\n",
        "    help='Choose architecture.')\n",
        "# Optimization options\n",
        "parser.add_argument(\n",
        "    '--epochs', '-e', type=int, default=100, help='Number of epochs to train.')\n",
        "parser.add_argument(\n",
        "    '--learning-rate',\n",
        "    '-lr',\n",
        "    type=float,\n",
        "    default=0.1,\n",
        "    help='Initial learning rate.')\n",
        "parser.add_argument(\n",
        "    '--batch-size', '-b', type=int, default=128, help='Batch size.')\n",
        "parser.add_argument('--eval-batch-size', type=int, default=1000)\n",
        "parser.add_argument('--momentum', type=float, default=0.9, help='Momentum.')\n",
        "parser.add_argument(\n",
        "    '--decay',\n",
        "    '-wd',\n",
        "    type=float,\n",
        "    default=0.0005,\n",
        "    help='Weight decay (L2 penalty).')\n",
        "# WRN Architecture options\n",
        "parser.add_argument(\n",
        "    '--layers', default=40, type=int, help='total number of layers')\n",
        "parser.add_argument('--widen-factor', default=2, type=int, help='Widen factor')\n",
        "parser.add_argument(\n",
        "    '--droprate', default=0.0, type=float, help='Dropout probability')\n",
        "# AugMix options\n",
        "parser.add_argument(\n",
        "    '--mixture-width',\n",
        "    default=3,\n",
        "    type=int,\n",
        "    help='Number of augmentation chains to mix per augmented example')\n",
        "parser.add_argument(\n",
        "    '--mixture-depth',\n",
        "    default=-1,\n",
        "    type=int,\n",
        "    help='Depth of augmentation chains. -1 denotes stochastic depth in [1, 3]')\n",
        "parser.add_argument(\n",
        "    '--aug-severity',\n",
        "    default=3,\n",
        "    type=int,\n",
        "    help='Severity of base augmentation operators')\n",
        "parser.add_argument(\n",
        "    '--no-jsd',\n",
        "    '-nj',\n",
        "    action='store_true',\n",
        "    help='Turn off JSD consistency loss.')\n",
        "parser.add_argument(\n",
        "    '--all-ops',\n",
        "    '-all',\n",
        "    action='store_true',\n",
        "    help='Turn on all operations (+brightness,contrast,color,sharpness).')\n",
        "# Checkpointing options\n",
        "parser.add_argument(\n",
        "    '--save',\n",
        "    '-s',\n",
        "    type=str,\n",
        "    default='./snapshots',\n",
        "    help='Folder to save checkpoints.')\n",
        "parser.add_argument(\n",
        "    '--resume',\n",
        "    '-r',\n",
        "    type=str,\n",
        "    default='',\n",
        "    help='Checkpoint path for resume / test.')\n",
        "parser.add_argument('--evaluate', action='store_true', help='Eval only.')\n",
        "parser.add_argument(\n",
        "    '--print-freq',\n",
        "    type=int,\n",
        "    default=50,\n",
        "    help='Training loss print frequency (batches).')\n",
        "# Acceleration\n",
        "parser.add_argument(\n",
        "    '--num-workers',\n",
        "    type=int,\n",
        "    default=4,\n",
        "    help='Number of pre-fetching threads.')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "CORRUPTIONS = [\n",
        "    'gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur',\n",
        "    'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog',\n",
        "    'brightness', 'contrast', 'elastic_transform', 'pixelate',\n",
        "    'jpeg_compression'\n",
        "]\n",
        "\n",
        "\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "    \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "\n",
        "def aug(image, preprocess):\n",
        "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "    Args:\n",
        "    image: PIL.Image input image\n",
        "    preprocess: Preprocessing function which should return a torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "    \"\"\"\n",
        "    aug_list = augmentations.augmentations\n",
        "    if args.all_ops:\n",
        "        aug_list = augmentations.augmentations_all\n",
        "\n",
        "    ws = np.float32(np.random.dirichlet([1] * args.mixture_width))\n",
        "    m = np.float32(np.random.beta(1, 1))\n",
        "\n",
        "    mix = torch.zeros_like(preprocess(image))\n",
        "    for i in range(args.mixture_width):\n",
        "        image_aug = image.copy()\n",
        "        depth = args.mixture_depth if args.mixture_depth > 0 else np.random.randint(1, 4)\n",
        "        for _ in range(depth):\n",
        "            op = np.random.choice(aug_list)\n",
        "            image_aug = op(image_aug, args.aug_severity)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image_aug)\n",
        "\n",
        "    mixed = (1 - m) * preprocess(image) + m * mix\n",
        "    return mixed\n",
        "\n",
        "\n",
        "class AugMixDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset wrapper to perform AugMix augmentation.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, preprocess, no_jsd=False):\n",
        "        self.dataset = dataset\n",
        "        self.preprocess = preprocess\n",
        "        self.no_jsd = no_jsd\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.dataset[i]\n",
        "        if self.no_jsd:\n",
        "            return aug(x, self.preprocess), y\n",
        "        else:\n",
        "            im_tuple = (self.preprocess(x), aug(x, self.preprocess), aug(x, self.preprocess))\n",
        "        return im_tuple, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def train(net, train_loader, optimizer, scheduler):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    net.train()\n",
        "    loss_ema = 0.\n",
        "    for i, (images, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if args.no_jsd:\n",
        "        images = images.cuda()\n",
        "        targets = targets.cuda()\n",
        "        logits = net(images)\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "        images_all = torch.cat(images, 0).cuda()\n",
        "        targets = targets.cuda()\n",
        "        logits_all = net(images_all)\n",
        "        logits_clean, logits_aug1, logits_aug2 = torch.split(logits_all, images[0].size(0))\n",
        "\n",
        "        # Cross-entropy is only computed on clean images\n",
        "        loss = F.cross_entropy(logits_clean, targets)\n",
        "\n",
        "        p_clean, p_aug1, p_aug2 = F.softmax(logits_clean, dim=1), F.softmax(logits_aug1, dim=1), F.softmax(logits_aug2,\n",
        "                                                                                                           dim=1)\n",
        "\n",
        "        # Clamp mixture distribution to avoid exploding KL divergence\n",
        "        p_mixture = torch.clamp((p_clean + p_aug1 + p_aug2) / 3., 1e-7, 1).log()\n",
        "        loss += 12 * (F.kl_div(p_mixture, p_clean, reduction='batchmean') +\n",
        "                      F.kl_div(p_mixture, p_aug1, reduction='batchmean') +\n",
        "                      F.kl_div(p_mixture, p_aug2, reduction='batchmean')) / 3.\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    loss_ema = loss_ema * 0.9 + float(loss) * 0.1\n",
        "    if i % args.print_freq == 0:\n",
        "        print('Train Loss {:.3f}'.format(loss_ema))\n",
        "\n",
        "    return loss_ema\n",
        "\n",
        "\n",
        "def test(net, test_loader):\n",
        "    \"\"\"Evaluate network on given dataset.\"\"\"\n",
        "    net.eval()\n",
        "    total_loss = 0.\n",
        "    total_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in test_loader:\n",
        "            images, targets = images.cuda(), targets.cuda()\n",
        "            logits = net(images)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            pred = logits.data.max(1)[1]\n",
        "            total_loss += float(loss.data)\n",
        "            total_correct += pred.eq(targets.data).sum().item()\n",
        "\n",
        "    return total_loss / len(test_loader.dataset), total_correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def test_c(net, test_data, base_path):\n",
        "    \"\"\"Evaluate network on given corrupted dataset.\"\"\"\n",
        "    corruption_accs = []\n",
        "    for corruption in CORRUPTIONS:\n",
        "        # Reference to original data is mutated\n",
        "        test_data.data = np.load(base_path + corruption + '.npy')\n",
        "        test_data.targets = torch.LongTensor(np.load(base_path + 'labels.npy'))\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_data,\n",
        "            batch_size=args.eval_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=args.num_workers,\n",
        "            pin_memory=True)\n",
        "\n",
        "        test_loss, test_acc = test(net, test_loader)\n",
        "        corruption_accs.append(test_acc)\n",
        "        print('{}\\n\\tTest Loss {:.3f} | Test Error {:.3f}'.format(corruption, test_loss, 100 - 100. * test_acc))\n",
        "\n",
        "    return np.mean(corruption_accs)\n",
        "\n",
        "\n",
        "def main():\n",
        "    torch.manual_seed(1)\n",
        "    np.random.seed(1)\n",
        "\n",
        "    # Load datasets\n",
        "    train_transform = transforms.Compose(\n",
        "        [transforms.RandomHorizontalFlip(),\n",
        "         transforms.RandomCrop(32, padding=4)])\n",
        "    preprocess = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize([0.5] * 3, [0.5] * 3)])\n",
        "    test_transform = preprocess\n",
        "\n",
        "    if args.dataset == 'cifar10':\n",
        "        train_data = datasets.CIFAR10('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "        test_data = datasets.CIFAR10('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "        base_c_path = './data/cifar/CIFAR-10-C/'\n",
        "        num_classes = 10\n",
        "    else:\n",
        "        train_data = datasets.CIFAR100('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "        test_data = datasets.CIFAR100('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "        base_c_path = './data/cifar/CIFAR-100-C/'\n",
        "        num_classes = 100\n",
        "\n",
        "    train_data = AugMixDataset(train_data, preprocess, args.no_jsd)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_data,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.num_workers,\n",
        "        pin_memory=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        batch_size=args.eval_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # Create model\n",
        "    if args.model == 'densenet':\n",
        "        net = densenet(num_classes=num_classes)\n",
        "    elif args.model == 'wrn':\n",
        "        net = WideResNet(args.layers, num_classes, args.widen_factor, args.droprate)\n",
        "    elif args.model == 'allconv':\n",
        "        net = AllConvNet(num_classes)\n",
        "    elif args.model == 'resnext':\n",
        "        net = resnext29(num_classes=num_classes)\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        net.parameters(),\n",
        "        args.learning_rate,\n",
        "        momentum=args.momentum,\n",
        "        weight_decay=args.decay,\n",
        "        nesterov=True)\n",
        "\n",
        "    # Distribute model across all visible GPUs\n",
        "    net = torch.nn.DataParallel(net).cuda()\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    start_epoch = 0\n",
        "\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            start_epoch = checkpoint['epoch'] + 1\n",
        "            best_acc = checkpoint['best_acc']\n",
        "            net.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print('Model restored from epoch:', start_epoch)\n",
        "\n",
        "    if args.evaluate:\n",
        "        # Evaluate clean accuracy first because test_c mutates underlying data\n",
        "        test_loss, test_acc = test(net, test_loader)\n",
        "        print('Clean\\n\\tTest Loss {:.3f} | Test Error {:.2f}'.format(\n",
        "            test_loss, 100 - 100. * test_acc))\n",
        "\n",
        "        test_c_acc = test_c(net, test_data, base_c_path)\n",
        "        print('Mean Corruption Error: {:.3f}'.format(100 - 100. * test_c_acc))\n",
        "        return\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "            step,\n",
        "            args.epochs * len(train_loader),\n",
        "            1,  # lr_lambda computes multiplicative factor\n",
        "            1e-6 / args.learning_rate))\n",
        "\n",
        "    if not os.path.exists(args.save):\n",
        "        os.makedirs(args.save)\n",
        "    if not os.path.isdir(args.save):\n",
        "        raise Exception('%s is not a dir' % args.save)\n",
        "\n",
        "    log_path = os.path.join(args.save,\n",
        "                            args.dataset + '_' + args.model + '_training_log.csv')\n",
        "    with open(log_path, 'w') as f:\n",
        "        f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
        "\n",
        "    best_acc = 0\n",
        "    print('Beginning training from epoch:', start_epoch + 1)\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        begin_time = time.time()\n",
        "\n",
        "    train_loss_ema = train(net, train_loader, optimizer, scheduler)\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "\n",
        "    is_best = test_acc > best_acc\n",
        "    best_acc = max(test_acc, best_acc)\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'dataset': args.dataset,\n",
        "        'model': args.model,\n",
        "        'state_dict': net.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    save_path = os.path.join(args.save, 'checkpoint.pth.tar')\n",
        "    torch.save(checkpoint, save_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(save_path, os.path.join(args.save, 'model_best.pth.tar'))\n",
        "\n",
        "    with open(log_path, 'a') as f:\n",
        "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
        "            (epoch + 1),\n",
        "            time.time() - begin_time,\n",
        "            train_loss_ema,\n",
        "            test_loss,\n",
        "            100 - 100. * test_acc,))\n",
        "\n",
        "    print(\n",
        "        'Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} |'\n",
        "        ' Test Error {4:.2f}'\n",
        "        .format((epoch + 1), int(time.time() - begin_time), train_loss_ema,\n",
        "                test_loss, 100 - 100. * test_acc))\n",
        "\n",
        "    test_c_acc = test_c(net, test_data, base_c_path)\n",
        "    print('Mean Corruption Error: {:.3f}'.format(100 - 100. * test_c_acc))\n",
        "\n",
        "    with open(log_path, 'a') as f:\n",
        "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' %\n",
        "                (args.epochs + 1, 0, 0, 0, 100 - 100 * test_c_acc))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "QOmxiiYhjZkc",
        "outputId": "63c08457-fe1a-4aa9-920e-72b39a68903e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c0c6da65c4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#import augmentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mallconv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAllConvNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allconv'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}